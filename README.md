# CS441 Homework 2 Submission by Omar Carrillo
Welcome to my submission for Homework 2. Below I will layout the files in my program and their uses. Video link for demo: https://youtu.be/EzrW624_ZPo


# Configuration Files application.conf (src/main/resources) in ScalaPB and ScalaRESTful
It also allows for the passing of parameters that change the task's behavior:
- port: The port that the server listens on (used for ScalaPB client server)
- address: The address that ther server opens on (used for ScalaPB client server)
- lambdaAPI: The URI for the API gateway for the respective lambda function 

Logger in logback.xml used for logging in both programs

# Utility Objects HelperUtils (src/main/scala/HelperUtils)
Using the CreateLogger and ObtainConfig reference for grabbing configuarition values and logging program activities.



# ScalaPB gRPC Client Server (ScalaPB @ a457939)
Here I have the project for gRPC client server that uses ScalaPB and protobufs to communicate.
After cloning the project into Intellij everything should compile with no issue running 'sbt compile' after opening up the terminal.

(src/main/scala)

In this folder are the two main scala files relevant to running the project: lambdaQueryServer.scala and main.scala.
The client and server applications can be run in two different ways:
- Using two different terminals and sbt, by using the 'sbt run' command user is asked for to input the number option 1 or 2 after compiling. 1 being the option for the   server and 2 being the option for the client. 
- In the first terminal the user can just use 'sbt run' and select option 1 for the server to begin listening. Then in       another terminal start the client with its   arguments. 
- An example of this would be sbt "run 17:00:00.000 01:00:00.000" this passes the time stamps to the client for it   to send to the server then inside the server send     the time stamps to the lambda function for it to check the interval 17:00:00.000 - 18:00:00.000. The return message   from the log function can be seen in a log         messsage inside the terminal you invoked the client in.


# mainRun (src/main/scala/mainRun)
The main Scala object that creates instances of the MapReduceProgram tasks and runs their Map and Reduce job with the use of the logger to confirm succesful job completions.

# Running the program in mainRun -> main
The function takes in two command line arguments: first one as the input directory for the tasks and the second as the output directory.
If you would run with sbt it would look like this: sbt "run inputDirectory outputDirectory" (quotes inclduded). An example using content root inside the program:
> sbt "run src/main/resources/input src/main/resources/output"

Editing the run configurations for Intellij allows you to add command line arguments allowing you to run the program this way as well

Before running:
The input directory should exist with a text file suitable for Hadoop MapReduce jobs to input and run such as .txt or .log files
Log file should be of the format of log files generated by LogFileGenerator or unexpected outputs could occur.

There should be no matching output directory to the output directory the user inputs or writes in HW1Configs.conf, this will cause the map and reduce jobs not to run.

# Tests (src/main/test/Generation/MRLogic.scala)
Tests for logic used inside of the mappers for the MapReduceProgramTasks can be found here, various string parsing and Date manipulation. 
